{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key: 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N11Ee3GJmywu",
    "outputId": "64e10b54-dad3-48e2-c266-617670a17e82"
   },
   "outputs": [],
   "source": [
    "#pip install openai wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q2A8TGhKm3i5"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E9HEMJSX-3T"
   },
   "source": [
    "# 1.) Set up OpenAI and the enviornment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4zwwdkZDYDZN"
   },
   "outputs": [],
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8IiKS0snlpYP"
   },
   "outputs": [],
   "source": [
    "apikey = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key = openai.api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# client = openai.OpenAI()\n",
    "\n",
    "# try:\n",
    "#     chat_completions = client.chat.completions.create(\n",
    "#         model=\"gpt-4\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"I will be giving you an article. I am looking for false information. Please concisely list only the false information found. I want to capture all potentially false information, even if the potential is small.\"},\n",
    "#             {\"role\": \"user\", \"content\": content[:8180]}  # Ensure 'content' is defined\n",
    "#         ]\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOXc5_BTm9HP"
   },
   "source": [
    "# 2.) Use the wikipedia api to get a function that pulls in the text of a wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-v7OYamHlrEB"
   },
   "outputs": [],
   "source": [
    "page_titles = [\"Aritificial Intelligence\", \"UCLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_title = page_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = wikipedia.search(page_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wikipedia.page(search_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TgY2FkTdmhTH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API_URL',\n",
       " 'BeautifulSoup',\n",
       " 'Decimal',\n",
       " 'DisambiguationError',\n",
       " 'HTTPTimeoutError',\n",
       " 'ODD_ERROR_MESSAGE',\n",
       " 'PageError',\n",
       " 'RATE_LIMIT',\n",
       " 'RATE_LIMIT_LAST_CALL',\n",
       " 'RATE_LIMIT_MIN_WAIT',\n",
       " 'RedirectError',\n",
       " 'USER_AGENT',\n",
       " 'WikipediaException',\n",
       " 'WikipediaPage',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'cache',\n",
       " 'datetime',\n",
       " 'debug',\n",
       " 'donate',\n",
       " 'exceptions',\n",
       " 'geosearch',\n",
       " 'languages',\n",
       " 'page',\n",
       " 'random',\n",
       " 're',\n",
       " 'requests',\n",
       " 'search',\n",
       " 'set_lang',\n",
       " 'set_rate_limiting',\n",
       " 'set_user_agent',\n",
       " 'stdout_encode',\n",
       " 'suggest',\n",
       " 'summary',\n",
       " 'sys',\n",
       " 'time',\n",
       " 'timedelta',\n",
       " 'unicode_literals',\n",
       " 'util',\n",
       " 'wikipedia']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Kw5H5jMlmmS3"
   },
   "outputs": [],
   "source": [
    "#page.content\n",
    "def get_wikipedia_content(page_title):\n",
    "    search_results = wikipedia.search(page_title)\n",
    "    page = wikipedia.page(search_results[0])\n",
    "    return(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZF3BiZyXltYO"
   },
   "outputs": [],
   "source": [
    "content = get_wikipedia_content(page_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9aruncMmubX"
   },
   "source": [
    "# 3.) Build a chatgpt bot that will analyze the text given and try to locate any false info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Bmai3B6Dmw3O"
   },
   "outputs": [],
   "source": [
    "chat_completions = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\": \"I will be giving you an article. I am looking for false information. Please concisely list only the false information found. I want to capture all potentially false information, even if the potential is small.\"},\n",
    "        {\"role\" : \"user\", \"content\": content[:8180]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1jI-un5PnDjg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1. The sentence \"The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function.\" is false. The signal is not necessarily a real number; it can also be a vector of real numbers.\\n\\n2. The sentence \"A network is typically called a deep neural network if it has at least 2 hidden layers.\" is incorrect. Some sources define deep neural networks as networks with more than 2 hidden layers.\\n\\n3. The sentence \"Neural networks are typically trained through empirical risk minimization.\" is incomplete as not all neural networks are typically trained this way. Other methods like gradient descent, and stochastic gradient descent are also used.\\n\\n4. The sentence \"This method allows the network to generalize to unseen data.\" is misleading. While training aims to allow generalization, it doesn\\'t guarantee it, overfitting can still occur. \\n\\n5. The sentence \"In 1972, Shun\\'ichi Amari described an adaptive version of this architecture...\" is incorrect as Amari\\'s model came after and was influenced by Hopfield\\'s work in 1982.\\n\\n6. The sentence \"In 1969, [Fukushima] also introduced the ReLU (rectified linear unit) activation function.\" is false as ReLU was introduced later in 2000 by Hahnloser et al. \\n\\n7. The sentence \"The term \"back-propagating errors\" was introduced in 1962 by Frank Rosenblatt\" is incorrect. The back-propagation algorithm was attributed to Paul Werbos during the 1970s.', role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completions.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_TMKFGN4nDJ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The sentence \"The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function.\" is false. The signal is not necessarily a real number; it can also be a vector of real numbers.\n",
      "\n",
      "2. The sentence \"A network is typically called a deep neural network if it has at least 2 hidden layers.\" is incorrect. Some sources define deep neural networks as networks with more than 2 hidden layers.\n",
      "\n",
      "3. The sentence \"Neural networks are typically trained through empirical risk minimization.\" is incomplete as not all neural networks are typically trained this way. Other methods like gradient descent, and stochastic gradient descent are also used.\n",
      "\n",
      "4. The sentence \"This method allows the network to generalize to unseen data.\" is misleading. While training aims to allow generalization, it doesn't guarantee it, overfitting can still occur. \n",
      "\n",
      "5. The sentence \"In 1972, Shun'ichi Amari described an adaptive version of this architecture...\" is incorrect as Amari's model came after and was influenced by Hopfield's work in 1982.\n",
      "\n",
      "6. The sentence \"In 1969, [Fukushima] also introduced the ReLU (rectified linear unit) activation function.\" is false as ReLU was introduced later in 2000 by Hahnloser et al. \n",
      "\n",
      "7. The sentence \"The term \"back-propagating errors\" was introduced in 1962 by Frank Rosenblatt\" is incorrect. The back-propagation algorithm was attributed to Paul Werbos during the 1970s.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6FKAJVXSoayA"
   },
   "outputs": [],
   "source": [
    "def chatgpt_error_correction(text):\n",
    "    chat_completions = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\": \"I will be giving you an article. I am looking for false information. Please concisely list only the false information found. I want to capture all potentially false information, even if the potential is small.\"},\n",
    "        {\"role\" : \"user\", \"content\": text[:8180]}]\n",
    "    )\n",
    "    print(chat_completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPw5LyPEobmk"
   },
   "source": [
    "# 4.) Make a for loop and check a few wikipedia pages and return a report of any potentially false info via wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "V7cuhML2ocGn"
   },
   "outputs": [],
   "source": [
    "page_titles = [\"Aritificial Intelligence\", \"UCLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia's article of Aritificial Intelligence\n",
      "- ANNs were invented by John Hopfield in 1982.\n",
      "- The first deep learning Multi Layer Perceptron (MLP) was published by Alexey Grigorevich Ivakhnenko and Valentin Lapa in 1965.\n",
      "- The convolutional neural network (CNN) architecture with convolutional layers and downsampling layers was introduced by Kunihiko Fukushima in 1980.\n",
      "- The rectified linear unit (ReLU) activation function was introduced in 1969 by Kunihiko Fukushima.\n",
      "- The term \"back-propagating errors\" was introduced in 1962 by Frank Rosenblatt.\n",
      "Wikipedia's article of UCLA\n",
      "- UCLA was not originally established as the southern branch of the California State Normal School and did not evolve into San José State University.\n",
      "- UCLA did not become the Southern Branch of UC in 1919.\n",
      "- UCLA does not have 337 undergraduate and graduate degree programs.\n",
      "- UCLA did not receive 174,914 undergraduate applications for Fall 2022.\n",
      "- UCLA is not the most applied-to university in the United States.\n",
      "- UCLA does not have six schools offering undergraduate degree programs.\n",
      "- UCLA has not won 121 NCAA team championships.\n",
      "- UCLA has not had 410 Bruins make Olympic teams.\n",
      "- The claim that UCLA has had a gold medalist in every Olympics in which the U.S. has participated since 1932 is false.\n",
      "- The claim that UCLA has had 27 Nobel laureates, five Turing Award winners, two Chief Scientists of the U.S. Air Force, and one Fields Medalist affiliated with it is false.\n",
      "- The claim that 55 associated faculty members of UCLA have been elected to the National Academy of Sciences, 29 to the National Academy of Engineering, 41 to the National Academy of Medicine, and 156 to the American Academy of Arts and Sciences is false.\n",
      "- The claim that UCLA was elected to the Association of American Universities in 1974 is false.\n"
     ]
    }
   ],
   "source": [
    "for page_title in page_titles:\n",
    "    try:\n",
    "        print(\"Wikipedia's article of \" + page_title)\n",
    "        content = get_wikipedia_content(page_title)\n",
    "        chatgpt_error_correction(content)\n",
    "    except:\n",
    "        print(\"ERROR\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
